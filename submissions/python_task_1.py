# -*- coding: utf-8 -*-
"""python_task_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BkGVxECUa_fxMwiWRdemVoUFwbktHBEj
"""



"""# New Section"""

from google.colab import drive
drive.mount('/content/drive')

"""Under the function named generate_car_matrix write a logic that takes the dataset-1.csv as a DataFrame. Return a new DataFrame that follows the following rules:

values from id_2 as columns
values from id_1 as index
dataframe should have values from car column
diagonal values should be 0.
"""

import pandas as pd
import numpy as np

def generate_car_matrix(df):
    # set column 'id_1' as the index
    df.set_index('id_1', inplace=True)
    # sorting the index in ascending order
    df_sorted = df.sort_values(by='id_1')

    # Create a new DataFrame with 'id_2' as columns and 'car' values
    result_df = df.pivot(columns='id_2', values='car')

    # Set diagonal values to 0
    np.fill_diagonal(result_df.values, 0)

    return result_df

# Read the CSV and call the function
df = pd.read_csv(r"/dataset_1.csv")
result_matrix = generate_car_matrix(df)

# Display the result DataFrame
print(result_matrix)

"""Question 2: Car Type Count Calculation
Create a Python function named get_type_count that takes the dataset-1.csv as a DataFrame. Add a new categorical column car_type based on values of the column car:

low for values less than or equal to 15,
medium for values greater than 15 and less than or equal to 25,
high for values greater than 25.
Calculate the count of occurrences for each car_type category and return the result as a dictionary. Sort the dictionary alphabetically based on keys.
"""

import pandas as pd

def get_type_count(df):
    # Add a new column 'car_type' based on 'car' column values
    df['car_type'] = pd.cut(df['car'], bins=[-float('inf'), 15, 25, float('inf')],
                            labels=['low', 'medium', 'high'], right=False)

    # Calculate the count of occurrences for each 'car_type' category
    type_count = df['car_type'].value_counts().to_dict()

    # Sort the dictionary alphabetically based on keys
    sorted_type_count = dict(sorted(type_count.items()))

    return sorted_type_count

# Read the CSV and call the function
df = pd.read_csv(r"/dataset_1.csv")
result_type_count = get_type_count(df)

# Display the result dictionary
print(result_type_count)

"""Question 3: Bus Count Index Retrieval
Create a Python function named get_bus_indexes that takes the dataset-1.csv as a DataFrame. The function should identify and return the indices as a list (sorted in ascending order) where the bus values are greater than twice the mean value of the bus column in the DataFrame.
"""

def get_bus_indexes(df):

    # Calculate the mean value of the 'bus' column
    bus_mean = df['bus'].mean()

    # Identify indices where 'bus' values are greater than twice the mean
    bus_indexes = df[df['bus'] > 2 * bus_mean].index.tolist()

    # Sort the indices in ascending order
    bus_indexes.sort()

    return bus_indexes

# Read the CSV and call the function
df = pd.read_csv(r"/dataset_1.csv")
result_bus_indexes = get_bus_indexes(df)

# Display the result list of indices
print(result_bus_indexes)

"""Question 4: Route Filtering
Create a python function filter_routes that takes the dataset-1.csv as a DataFrame. The function should return the sorted list of values of column route for which the average of values of truck column is greater than 7.
"""

import pandas as pd

def filter_routes(df):
    # Group by 'route' and calculate the average of 'truck' column for each group
    route_avg_truck = df.groupby('route')['truck'].mean()

    # Filter routes where the average of 'truck' column is greater than 7
    filtered_routes = route_avg_truck[route_avg_truck > 7].index.tolist()

    # Sort the list of routes
    filtered_routes.sort()

    return filtered_routes

# Read the CSV and call the function
df = pd.read_csv(r"/dataset_1.csv")
result_filtered_routes = filter_routes(df)

# Display the result list of filtered routes
print(result_filtered_routes)

"""Question 5: Matrix Value Modification
Create a Python function named multiply_matrix that takes the resulting DataFrame from Question 1, as input and modifies each value according to the following logic:

If a value in the DataFrame is greater than 20, multiply those values by 0.75,
If a value is 20 or less, multiply those values by 1.25.
The function should return the modified DataFrame which has values rounded to 1 decimal place.
"""

import pandas as pd

def multiply_matrix(df):
    # Use applymap to modify each value in the DataFrame based on the specified logic
    modified_df = df.applymap(lambda x: x * 0.75 if x > 20 else x * 1.25)

    # Round the values to 1 decimal place
    modified_df = modified_df.round(1)

    return modified_df

# Call the function and display the modified DataFrame
result_modified = multiply_matrix(result_matrix)
print(result_modified)

"""you are given a dataset, dataset-2.csv, containing columns id, id_2, and timestamp (startDay, startTime, endDay, endTime). The goal is to verify the completeness of the time data by checking whether the timestamps for each unique (id, id_2) pair cover a full 24-hour period (from 12:00:00 AM to 11:59:59 PM) and span all 7 days of the week (from Monday to Sunday).

## Create a function that accepts dataset-2.csv as a DataFrame and returns a boolean series that indicates if each (id, id_2) pair has incorrect timestamps. The boolean series must have multi-index (id, id_2).
"""

import pandas as pd

def verify_timestamp_completeness(data):
    # Convert startDay and endDay to categorical with proper ordering
    days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    data['startDay'] = pd.Categorical(data['startDay'], categories=days_order, ordered=True)
    data['endDay'] = pd.Categorical(data['endDay'], categories=days_order, ordered=True)

    # Convert time columns to datetime objects
    data['startTime'] = pd.to_datetime(data['startTime'])
    data['endTime'] = pd.to_datetime(data['endTime'])

    # Convert categorical days to numeric values for subtraction
    data['startDayNum'] = data['startDay'].cat.codes
    data['endDayNum'] = data['endDay'].cat.codes

    # Create a boolean series to check if timestamps are incorrect
    incorrect_timestamps = (
        (data['endTime'] - data['startTime'] != pd.Timedelta(days=1)) |
        (data['endDayNum'] - data['startDayNum'] != 1)
    )

    # Group by (id, id_2) and check if any pair has incorrect timestamps
    result = data.groupby(['id', 'id_2']).apply(lambda x: any(incorrect_timestamps[x.index]))

    return result

# Assuming your DataFrame is named 'df'
result_series = verify_timestamp_completeness(df)

# Display the result
print(result_series)
